# Part 1.1: Hugging Face Hub 이해하기

---

## 학습 목표
- Hub의 핵심 구조 (Models, Datasets, Spaces) 이해
- Model Card 메타데이터 읽기 및 활용
- `huggingface_hub` 라이브러리로 프로그래매틱 접근

---

## 1. Hub 개요

### Hub란?
- 200만+ 모델, 50만+ 데이터셋, 100만+ Spaces 호스팅
- Git 기반 버전 관리
- 오픈소스 ML 협업 플랫폼

### 3대 핵심 구성요소

| 구분 | 설명 | URL 패턴 |
|------|------|----------|
| **Models** | 사전학습/파인튜닝 모델 | `huggingface.co/{user}/{model}` |
| **Datasets** | 학습용 데이터셋 | `huggingface.co/datasets/{user}/{dataset}` |
| **Spaces** | Gradio/Streamlit 데모 앱 | `huggingface.co/spaces/{user}/{space}` |

---

## 2. 환경 설정

### 설치
```bash
# 기본 설치
pip install huggingface_hub

# CLI 도구 포함 설치 (권장)
pip install huggingface_hub[cli]

# 고속 다운로드 지원 (선택)
pip install huggingface_hub[hf_xet]
```

### 인증 (Authentication)
```bash
# CLI 로그인 (대화형)
hf auth login

# 환경변수로 토큰 전달
hf auth login --token $HF_TOKEN
```

```python
# Python에서 로그인
from huggingface_hub import login

# 대화형
login()

# 토큰 직접 전달
login(token="hf_xxxxx")
```

**토큰 발급**: https://huggingface.co/settings/tokens
- `read`: 다운로드 전용
- `write`: 업로드/생성 권한

---

## 3. 모델 검색 및 탐색

### 3.1 HfApi로 모델 검색

```python
from huggingface_hub import HfApi

api = HfApi()

# 기본 검색: 다운로드 수 기준 상위 5개
models = api.list_models(
    sort="downloads",
    direction=-1,
    limit=5
)

for model in models:
    print(f"{model.id} - Downloads: {model.downloads:,}")
```

**출력 예시:**
```
meta-llama/Llama-3.2-1B - Downloads: 12,345,678
openai/whisper-large-v3 - Downloads: 9,876,543
...
```

### 3.2 필터링 검색

```python
# Task + Library + Dataset 복합 필터
models = api.list_models(
    task="image-classification",      # Task 필터
    library="pytorch",                 # 프레임워크
    trained_dataset="imagenet",        # 학습 데이터셋
    limit=10
)

for m in models:
    print(f"{m.id} | {m.pipeline_tag} | {m.library_name}")
```

### 3.3 VLM/Vision 모델 검색 (실무 예시)

```python
# Vision-Language 모델 찾기
vlm_models = api.list_models(
    task="image-text-to-text",
    sort="downloads",
    limit=20
)

print("=== Top VLM Models ===")
for m in vlm_models:
    print(f"- {m.id}")
```

```python
# 특정 조직의 모델만 검색
qwen_models = api.list_models(
    author="Qwen",
    sort="downloads",
    limit=10
)
```

### 3.4 데이터셋 검색

```python
# 한국어 데이터셋 검색
datasets = api.list_datasets(
    language="ko",
    sort="downloads",
    limit=10
)

for ds in datasets:
    print(f"{ds.id} - {ds.downloads:,} downloads")
```

### 3.5 CLI로 검색

```bash
# 모델 검색
hf models ls --search "llama" --sort downloads --limit 5

# 데이터셋 검색
hf datasets ls --author Qwen

# Spaces 검색
hf spaces ls --search "chatbot"

# 특정 모델 정보 조회
hf models info meta-llama/Llama-3.2-1B
```

---

## 4. Model Card 이해하기

### 4.1 Model Card 구조

Model Card = YAML 메타데이터 + Markdown 본문

```yaml
---
language: en
license: mit
library_name: transformers
tags:
  - image-classification
  - pytorch
datasets:
  - imagenet-1k
metrics:
  - accuracy
base_model: google/vit-base-patch16-224
pipeline_tag: image-classification
---

# Model Card for ViT-Base

This model is a Vision Transformer (ViT) ...
```

### 4.2 Model Card 로드 및 분석

```python
from huggingface_hub import ModelCard

# Hub에서 Model Card 로드
card = ModelCard.load("google/vit-base-patch16-224")

# 메타데이터 확인
print("=== Metadata ===")
print(card.data.to_dict())

# 주요 정보 추출
print(f"License: {card.data.license}")
print(f"Library: {card.data.library_name}")
print(f"Tags: {card.data.tags}")
print(f"Base Model: {card.data.base_model}")

# Markdown 본문
print("\n=== Card Text (first 500 chars) ===")
print(card.text[:500])
```

### 4.3 좋은 모델 선별 기준

```python
def evaluate_model_quality(model_id: str) -> dict:
    """모델 품질 평가 체크리스트"""
    api = HfApi()
    info = api.model_info(model_id, securityStatus=True)
    card = ModelCard.load(model_id)
    
    quality = {
        "model_id": model_id,
        "downloads": info.downloads,
        "likes": info.likes,
        "has_license": card.data.license is not None,
        "has_model_card": len(card.text) > 100,
        "library": card.data.library_name,
        "tags": card.data.tags or [],
        "security_status": info.security_status,
    }
    
    # 점수 계산 (간단한 휴리스틱)
    score = 0
    if quality["downloads"] > 10000: score += 2
    if quality["likes"] > 100: score += 1
    if quality["has_license"]: score += 2
    if quality["has_model_card"]: score += 2
    if quality["library"] in ["transformers", "diffusers", "sentence-transformers"]: score += 1
    
    quality["quality_score"] = score
    return quality

# 사용 예시
result = evaluate_model_quality("google/vit-base-patch16-224")
print(result)
```

### 4.4 Model Card 생성하기

```python
from huggingface_hub import ModelCard, ModelCardData

# 메타데이터 정의
card_data = ModelCardData(
    language="ko",
    license="apache-2.0",
    library_name="transformers",
    tags=["text-classification", "korean", "bert"],
    datasets=["klue"],
    metrics=["f1", "accuracy"],
    base_model="klue/bert-base",
    pipeline_tag="text-classification"
)

# Model Card 생성
card_content = f"""
---
{card_data.to_yaml()}
---

# My Korean BERT Classifier

## Model Description
한국어 텍스트 분류를 위한 BERT 기반 모델입니다.

## Training Data
- KLUE benchmark 데이터셋 사용

## Usage
```python
from transformers import pipeline
classifier = pipeline("text-classification", model="my-org/ko-bert-classifier")
result = classifier("이 영화 정말 재미있어요!")
```

## Limitations
- 구어체/신조어에 약함
- 최대 512 토큰
"""

card = ModelCard(card_content)

# Hub에 업로드
# card.push_to_hub("my-org/ko-bert-classifier")
```

---

## 5. 파일 다운로드

### 5.1 단일 파일 다운로드

```python
from huggingface_hub import hf_hub_download

# 특정 파일 다운로드
file_path = hf_hub_download(
    repo_id="gpt2",
    filename="config.json"
)
print(f"Downloaded to: {file_path}")

# 특정 revision (버전) 다운로드
file_path = hf_hub_download(
    repo_id="gpt2",
    filename="config.json",
    revision="main"  # branch, tag, commit hash
)

# 특정 디렉토리에 다운로드
file_path = hf_hub_download(
    repo_id="gpt2",
    filename="config.json",
    local_dir="./my_models/gpt2"
)
```

### 5.2 전체 저장소 다운로드

```python
from huggingface_hub import snapshot_download

# 전체 모델 다운로드
local_dir = snapshot_download(repo_id="gpt2")
print(f"Downloaded to: {local_dir}")

# 패턴 필터링: safetensors만 다운로드
local_dir = snapshot_download(
    repo_id="meta-llama/Llama-3.2-1B",
    allow_patterns=["*.safetensors", "*.json"],
    ignore_patterns=["*.bin", "*.h5"]
)

# 데이터셋 다운로드
local_dir = snapshot_download(
    repo_id="squad",
    repo_type="dataset"
)
```

### 5.3 CLI로 다운로드

```bash
# 단일 파일
hf download gpt2 config.json

# 여러 파일
hf download gpt2 config.json model.safetensors

# 패턴 필터링
hf download meta-llama/Llama-3.2-1B \
    --include "*.safetensors" \
    --exclude "*.fp16.*"

# 특정 디렉토리에 저장
hf download gpt2 --local-dir ./my_models/gpt2
```

---

## 6. 파일 업로드

### 6.1 저장소 생성

```python
from huggingface_hub import create_repo

# 모델 저장소 생성
repo_url = create_repo(
    repo_id="my-awesome-model",
    private=False,           # True면 비공개
    exist_ok=True           # 이미 존재하면 무시
)
print(f"Created: {repo_url}")

# 데이터셋 저장소 생성
repo_url = create_repo(
    repo_id="my-dataset",
    repo_type="dataset"
)

# Space 생성
repo_url = create_repo(
    repo_id="my-demo",
    repo_type="space",
    space_sdk="gradio"      # gradio, streamlit, docker
)
```

### 6.2 단일 파일 업로드

```python
from huggingface_hub import upload_file

# 파일 업로드
upload_file(
    path_or_fileobj="./model.safetensors",
    path_in_repo="model.safetensors",
    repo_id="username/my-model",
    commit_message="Add model weights"
)

# 바이트 객체 직접 업로드
upload_file(
    path_or_fileobj=b"Hello World",
    path_in_repo="hello.txt",
    repo_id="username/my-model"
)
```

### 6.3 폴더 업로드

```python
from huggingface_hub import upload_folder

# 전체 폴더 업로드
upload_folder(
    folder_path="./my_model",
    repo_id="username/my-model",
    commit_message="Upload full model"
)

# 패턴 필터링
upload_folder(
    folder_path="./my_model",
    repo_id="username/my-model",
    allow_patterns=["*.safetensors", "*.json", "*.md"],
    ignore_patterns=["*.pyc", "__pycache__", ".git"]
)

# Space 업로드
upload_folder(
    folder_path="./my_gradio_app",
    repo_id="username/my-demo",
    repo_type="space"
)
```

### 6.4 CLI로 업로드

```bash
# 파일 업로드
hf upload username/my-model ./model.safetensors

# 폴더 업로드
hf upload username/my-model ./my_model_folder

# 특정 경로에 업로드
hf upload username/my-model ./data /train_data
```

---

## 7. HfApi 고급 활용

### 7.1 모델 상세 정보 조회

```python
from huggingface_hub import HfApi

api = HfApi()

# 모델 메타데이터
info = api.model_info(
    "meta-llama/Llama-3.2-1B",
    securityStatus=True
)

print(f"Model ID: {info.id}")
print(f"Author: {info.author}")
print(f"Downloads: {info.downloads:,}")
print(f"Likes: {info.likes}")
print(f"Tags: {info.tags}")
print(f"Last Modified: {info.last_modified}")
print(f"Library: {info.library_name}")
print(f"Pipeline: {info.pipeline_tag}")

# 파일 목록
print("\n=== Files ===")
for sibling in info.siblings:
    print(f"  {sibling.rfilename} ({sibling.size:,} bytes)")
```

### 7.2 저장소 파일 관리

```python
# 파일 삭제
api.delete_file(
    path_in_repo="old_model.bin",
    repo_id="username/my-model",
    commit_message="Remove old weights"
)

# 저장소 삭제 (주의!)
api.delete_repo(
    repo_id="username/my-model",
    repo_type="model"
)

# 저장소 이동/이름 변경
api.move_repo(
    from_id="username/old-name",
    to_id="username/new-name"
)
```

### 7.3 저장소 가시성 변경

```python
# Private → Public
api.update_repo_visibility(
    repo_id="username/my-model",
    private=False
)
```

---

## 8. 실습 과제

### 과제 1: VLM 모델 탐색기
```python
"""
목표: Vision-Language 모델 Top 10 조회 및 분석
요구사항:
1. image-text-to-text task 모델 검색
2. 다운로드 수 기준 정렬
3. 각 모델의 license, base_model 정보 출력
"""

from huggingface_hub import HfApi, ModelCard

api = HfApi()

# TODO: 구현하기
```

### 과제 2: 커스텀 모델 업로드 파이프라인
```python
"""
목표: 학습된 모델을 Hub에 업로드하는 함수 작성
요구사항:
1. 저장소 생성 (없으면)
2. 모델 파일 업로드
3. Model Card 자동 생성 및 업로드
"""

def upload_model_to_hub(
    model_dir: str,
    repo_id: str,
    model_description: str,
    tags: list[str]
):
    # TODO: 구현하기
    pass
```

---

## 9. 참고 링크

### 공식 문서
- [Hub Documentation](https://huggingface.co/docs/hub)
- [huggingface_hub Quick Start](https://huggingface.co/docs/huggingface_hub/quick-start)
- [Download Guide](https://huggingface.co/docs/huggingface_hub/guides/download)
- [Upload Guide](https://huggingface.co/docs/huggingface_hub/guides/upload)
- [Search Guide](https://huggingface.co/docs/huggingface_hub/guides/search)
- [Model Cards Guide](https://huggingface.co/docs/huggingface_hub/guides/model-cards)
- [CLI Reference](https://huggingface.co/docs/huggingface_hub/guides/cli)

### API Reference
- [HfApi Reference](https://huggingface.co/docs/huggingface_hub/package_reference/hf_api)
- [File Download Reference](https://huggingface.co/docs/huggingface_hub/package_reference/file_download)
- [Repository Cards Reference](https://huggingface.co/docs/huggingface_hub/package_reference/cards)

### GitHub
- [huggingface_hub Repository](https://github.com/huggingface/huggingface_hub)

---

## 10. 핵심 요약

| 기능 | 함수/명령어 | 용도 |
|------|------------|------|
| 로그인 | `login()` / `hf auth login` | Hub 인증 |
| 모델 검색 | `api.list_models()` | 필터링 검색 |
| 파일 다운로드 | `hf_hub_download()` | 단일 파일 |
| 저장소 다운로드 | `snapshot_download()` | 전체 저장소 |
| 저장소 생성 | `create_repo()` | 새 저장소 |
| 파일 업로드 | `upload_file()` | 단일 파일 |
| 폴더 업로드 | `upload_folder()` | 전체 폴더 |
| Model Card 로드 | `ModelCard.load()` | 메타데이터 조회 |
| 모델 정보 | `api.model_info()` | 상세 정보 |