# Hugging Face íŠœí† ë¦¬ì–¼ Part 5.1: HF Agents / smolagents

## í•™ìŠµ ëª©í‘œ
- smolagents í”„ë ˆì„ì›Œí¬ ì´í•´ ë° ì„¤ì¹˜
- Tool ì •ì˜ ë°©ë²• (@tool ë°ì½”ë ˆì´í„°, Tool í´ë˜ìŠ¤)
- CodeAgent vs ToolCallingAgent ì°¨ì´ì 
- Multi-Agent ì‹œìŠ¤í…œ êµ¬ì¶•

---

## 1. smolagents ì†Œê°œ

### 1.1 smolagentsë€?

- **Hugging Face**ì—ì„œ ê°œë°œí•œ ê²½ëŸ‰ AI Agent í”„ë ˆì„ì›Œí¬
- í•µì‹¬ ë¡œì§ì´ **~1,000ì¤„**ì˜ ì½”ë“œë¡œ êµ¬ì„± (ìµœì†Œí•œì˜ ì¶”ìƒí™”)
- **Code Agent**: LLMì´ Python ì½”ë“œë¥¼ ì§ì ‘ ì‘ì„±í•˜ì—¬ ì‹¤í–‰
- 2024ë…„ 12ì›” ì¶œì‹œ, transformers.agentsì˜ í›„ì†

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     smolagents íŠ¹ì§•                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ¨ Simplicity     : ~1,000 lines of code                   â”‚
â”‚  ğŸ§‘â€ğŸ’» Code-First    : Python ì½”ë“œë¡œ ì•¡ì…˜ ì‹¤í–‰                 â”‚
â”‚  ğŸ¤— Hub Integration: Tool/Agent ê³µìœ  ë° ë¡œë“œ                 â”‚
â”‚  ğŸŒ Model-Agnostic : HF, OpenAI, Anthropic ë“± ì§€ì›          â”‚
â”‚  ğŸ‘ï¸ Modality-Agnostic: Text, Vision, Audio ì§€ì›            â”‚
â”‚  ğŸ› ï¸ Tool-Agnostic  : MCP, LangChain, Hub Space ì§€ì›         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Agent ë™ì‘ ì›ë¦¬ (ReAct íŒ¨í„´)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ReAct Loop                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Task â”€â”€â–¶ [Think] â”€â”€â–¶ [Act] â”€â”€â–¶ [Observe] â”€â”€â”             â”‚
â”‚              â”‚                                 â”‚             â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Loop â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                          â”‚                                  â”‚
â”‚                          â–¼                                  â”‚
â”‚                   [Final Answer]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Think**: ë¬¸ì œ ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½
2. **Act**: Tool í˜¸ì¶œ ë˜ëŠ” ì½”ë“œ ì‹¤í–‰
3. **Observe**: ê²°ê³¼ ê´€ì°° ë° í‰ê°€
4. **Repeat**: ëª©í‘œ ë‹¬ì„±ê¹Œì§€ ë°˜ë³µ

### 1.3 ì„¤ì¹˜

```bash
# ê¸°ë³¸ ì„¤ì¹˜
pip install smolagents

# ì¶”ê°€ ê¸°ëŠ¥ í¬í•¨ ì„¤ì¹˜
pip install "smolagents[toolkit]"      # ê¸°ë³¸ ë„êµ¬ í¬í•¨
pip install "smolagents[litellm]"      # LiteLLM ì§€ì›
pip install "smolagents[transformers]" # ë¡œì»¬ ëª¨ë¸ ì§€ì›
pip install "smolagents[gradio]"       # Gradio UI ì§€ì›
pip install "smolagents[mcp]"          # MCP ì„œë²„ ì§€ì›

# ì „ì²´ ì„¤ì¹˜
pip install "smolagents[all]"
```

### 1.4 HuggingFace ë¡œê·¸ì¸

```python
from huggingface_hub import login

# í† í°ìœ¼ë¡œ ë¡œê·¸ì¸ (https://hf.co/settings/tokens)
login("YOUR_HF_TOKEN")
```

---

## 2. ì²« ë²ˆì§¸ Agent ë§Œë“¤ê¸°

### 2.1 ê¸°ë³¸ Agent ìƒì„±

```python
from smolagents import CodeAgent, InferenceClientModel

# ëª¨ë¸ ì´ˆê¸°í™” (HF Inference API ì‚¬ìš©)
model = InferenceClientModel()  # ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©

# Agent ìƒì„±
agent = CodeAgent(tools=[], model=model)

# ì‹¤í–‰
result = agent.run("1ë¶€í„° 10ê¹Œì§€ì˜ í•©ì„ ê³„ì‚°í•´ì¤˜")
print(result)  # 55
```

### 2.2 Tool ì¶”ê°€í•˜ê¸°

```python
from smolagents import CodeAgent, InferenceClientModel, DuckDuckGoSearchTool

# ëª¨ë¸ ì´ˆê¸°í™”
model = InferenceClientModel()

# ê²€ìƒ‰ ë„êµ¬ì™€ í•¨ê»˜ Agent ìƒì„±
agent = CodeAgent(
    tools=[DuckDuckGoSearchTool()],
    model=model,
)

# ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
result = agent.run("í˜„ì¬ ëŒ€í•œë¯¼êµ­ ëŒ€í†µë ¹ì€ ëˆ„êµ¬ì¸ê°€ìš”?")
print(result)
```

### 2.3 ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ New run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ í˜„ì¬ ëŒ€í•œë¯¼êµ­ ëŒ€í†µë ¹ì€ ëˆ„êµ¬ì¸ê°€ìš”?                                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

=== Agent thoughts:
ëŒ€í•œë¯¼êµ­ì˜ í˜„ì¬ ëŒ€í†µë ¹ì„ ì°¾ê¸° ìœ„í•´ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤.

>>> Agent is executing the code below:
search_results = web_search("ëŒ€í•œë¯¼êµ­ í˜„ì¬ ëŒ€í†µë ¹ 2024")
print(search_results)

>>> Observation:
ìœ¤ì„ì—´ ëŒ€í†µë ¹ì€ 2022ë…„ 5ì›” 10ì¼ ì·¨ì„...

=== Agent thoughts:
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.

>>> Agent is executing the code below:
final_answer("í˜„ì¬ ëŒ€í•œë¯¼êµ­ì˜ ëŒ€í†µë ¹ì€ ìœ¤ì„ì—´ì…ë‹ˆë‹¤.")

Final answer: í˜„ì¬ ëŒ€í•œë¯¼êµ­ì˜ ëŒ€í†µë ¹ì€ ìœ¤ì„ì—´ì…ë‹ˆë‹¤.
```

---

## 3. Model ì„¤ì •

### 3.1 ì§€ì› ëª¨ë¸ í´ë˜ìŠ¤

| í´ë˜ìŠ¤ | ì„¤ëª… | ìš”êµ¬ì‚¬í•­ |
|--------|------|----------|
| `InferenceClientModel` | HF Inference API | HF Token |
| `LiteLLMModel` | 100+ LLM ì§€ì› | API Key |
| `TransformersModel` | ë¡œì»¬ ëª¨ë¸ | GPU/CPU |
| `OpenAIModel` | OpenAI í˜¸í™˜ API | API Key |

### 3.2 InferenceClientModel (HF API)

```python
from smolagents import InferenceClientModel

# ê¸°ë³¸ ëª¨ë¸ (ë¬´ë£Œ, Rate Limit ìˆìŒ)
model = InferenceClientModel()

# íŠ¹ì • ëª¨ë¸ ì§€ì •
model = InferenceClientModel(
    model_id="meta-llama/Llama-3.3-70B-Instruct",
    token="YOUR_HF_TOKEN",  # ì„ íƒì 
)

# ë‹¤ë¥¸ Provider ì‚¬ìš©
model = InferenceClientModel(
    model_id="Qwen/Qwen2.5-72B-Instruct",
    provider="together",  # together, sambanova, hyperbolic ë“±
)
```

### 3.3 LiteLLMModel (100+ LLM)

```python
from smolagents import LiteLLMModel
import os

# OpenAI
model = LiteLLMModel(
    model_id="gpt-4o",
    api_key=os.environ["OPENAI_API_KEY"],
)

# Anthropic Claude
model = LiteLLMModel(
    model_id="anthropic/claude-3-5-sonnet-latest",
    api_key=os.environ["ANTHROPIC_API_KEY"],
    temperature=0.2,
)

# AWS Bedrock
model = LiteLLMModel(
    model_id="bedrock/anthropic.claude-3-sonnet-20240229-v1:0",
)
```

### 3.4 TransformersModel (ë¡œì»¬)

```python
from smolagents import TransformersModel

# ë¡œì»¬ ëª¨ë¸ ë¡œë“œ
model = TransformersModel(
    model_id="Qwen/Qwen2.5-7B-Instruct",
    device_map="auto",
    max_new_tokens=4096,
)
```

### 3.5 OpenAIModel (OpenAI í˜¸í™˜)

```python
from smolagents import OpenAIModel
import os

# OpenAI ì§ì ‘ ì‚¬ìš©
model = OpenAIModel(
    model_id="gpt-4o",
    api_key=os.environ["OPENAI_API_KEY"],
)

# OpenRouter ì‚¬ìš©
model = OpenAIModel(
    model_id="openai/gpt-4o",
    api_base="https://openrouter.ai/api/v1",
    api_key=os.environ["OPENROUTER_API_KEY"],
)

# Together AI ì‚¬ìš©
model = OpenAIModel(
    model_id="meta-llama/Llama-3.3-70B-Instruct-Turbo",
    api_base="https://api.together.xyz/v1",
    api_key=os.environ["TOGETHER_API_KEY"],
)
```

---

## 4. Tool ì •ì˜í•˜ê¸°

### 4.1 Toolì˜ êµ¬ì„± ìš”ì†Œ

Toolì€ LLMì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¡œ, ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”:

| ìš”ì†Œ | ì„¤ëª… |
|------|------|
| `name` | ë„êµ¬ ì´ë¦„ |
| `description` | ë„êµ¬ ì„¤ëª… (LLMì´ ì–¸ì œ ì‚¬ìš©í• ì§€ íŒë‹¨) |
| `inputs` | ì…ë ¥ íŒŒë¼ë¯¸í„° (íƒ€ì…, ì„¤ëª…) |
| `output_type` | ì¶œë ¥ íƒ€ì… |

### 4.2 @tool ë°ì½”ë ˆì´í„° (ê°„ë‹¨í•œ ë°©ë²•)

```python
from smolagents import tool, CodeAgent, InferenceClientModel


@tool
def get_weather(city: str) -> str:
    """
    ì£¼ì–´ì§„ ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        city: ë‚ ì”¨ë¥¼ ì¡°íšŒí•  ë„ì‹œ ì´ë¦„
    
    Returns:
        ë‚ ì”¨ ì •ë³´ ë¬¸ìì—´
    """
    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, 15Â°C",
        "ë¶€ì‚°": "íë¦¼, 18Â°C",
        "ì œì£¼": "ë¹„, 20Â°C",
    }
    return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


@tool
def calculate_bmi(weight_kg: float, height_cm: float) -> str:
    """
    ì²´ì¤‘ê³¼ í‚¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ BMIë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        weight_kg: ì²´ì¤‘ (kg)
        height_cm: í‚¤ (cm)
    
    Returns:
        BMI ê°’ê³¼ íŒì • ê²°ê³¼
    """
    height_m = height_cm / 100
    bmi = weight_kg / (height_m ** 2)
    
    if bmi < 18.5:
        status = "ì €ì²´ì¤‘"
    elif bmi < 25:
        status = "ì •ìƒ"
    elif bmi < 30:
        status = "ê³¼ì²´ì¤‘"
    else:
        status = "ë¹„ë§Œ"
    
    return f"BMI: {bmi:.1f} ({status})"


# Agentì— Tool ì¶”ê°€
model = InferenceClientModel()
agent = CodeAgent(
    tools=[get_weather, calculate_bmi],
    model=model,
)

# ì‹¤í–‰
result = agent.run("ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ê³ , í‚¤ 175cm ëª¸ë¬´ê²Œ 70kgì¸ ì‚¬ëŒì˜ BMIë¥¼ ê³„ì‚°í•´ì¤˜")
print(result)
```

### 4.3 Tool í´ë˜ìŠ¤ (ê³ ê¸‰ ë°©ë²•)

```python
from smolagents import Tool
from huggingface_hub import list_models


class HFModelDownloadsTool(Tool):
    """HuggingFace Hubì—ì„œ ê°€ì¥ ë§ì´ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ì¡°íšŒ"""
    
    name = "model_download_counter"
    description = """
    ì£¼ì–´ì§„ íƒœìŠ¤í¬ì—ì„œ HuggingFace Hubì—ì„œ ê°€ì¥ ë§ì´ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    íƒœìŠ¤í¬ ì˜ˆì‹œ: 'text-generation', 'image-classification', 'text-to-image' ë“±
    """
    inputs = {
        "task": {
            "type": "string",
            "description": "ëª¨ë¸ì„ ê²€ìƒ‰í•  íƒœìŠ¤í¬ ì¢…ë¥˜",
        }
    }
    output_type = "string"
    
    def forward(self, task: str) -> str:
        """Tool ì‹¤í–‰ ë¡œì§"""
        try:
            models = list_models(filter=task, sort="downloads", direction=-1)
            top_model = next(iter(models))
            return f"ê°€ì¥ ì¸ê¸° ìˆëŠ” {task} ëª¨ë¸: {top_model.id} (ë‹¤ìš´ë¡œë“œ: {top_model.downloads:,})"
        except StopIteration:
            return f"'{task}' íƒœìŠ¤í¬ì— í•´ë‹¹í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# Tool ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‚¬ìš©
model_tool = HFModelDownloadsTool()

agent = CodeAgent(
    tools=[model_tool],
    model=InferenceClientModel(),
)

result = agent.run("text-to-image íƒœìŠ¤í¬ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ëª¨ë¸ì€ ë­ì•¼?")
print(result)
```

### 4.4 ìƒíƒœë¥¼ ê°€ì§„ Tool

```python
from smolagents import Tool
from typing import List


class TodoListTool(Tool):
    """í•  ì¼ ëª©ë¡ ê´€ë¦¬ ë„êµ¬"""
    
    name = "todo_manager"
    description = "í•  ì¼ ëª©ë¡ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. add, list, remove, clear ì•¡ì…˜ì„ ì§€ì›í•©ë‹ˆë‹¤."
    inputs = {
        "action": {
            "type": "string",
            "description": "ìˆ˜í–‰í•  ì•¡ì…˜: 'add', 'list', 'remove', 'clear'",
        },
        "item": {
            "type": "string",
            "description": "ì¶”ê°€í•˜ê±°ë‚˜ ì‚­ì œí•  í•­ëª© (add, remove ì‹œ í•„ìš”)",
            "nullable": True,
        }
    }
    output_type = "string"
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.todos: List[str] = []
    
    def forward(self, action: str, item: str = None) -> str:
        if action == "add":
            if item:
                self.todos.append(item)
                return f"'{item}' ì¶”ê°€ë¨. í˜„ì¬ {len(self.todos)}ê°œ í•­ëª©"
            return "ì¶”ê°€í•  í•­ëª©ì„ ì§€ì •í•´ì£¼ì„¸ìš”."
        
        elif action == "list":
            if not self.todos:
                return "í•  ì¼ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
            return "í•  ì¼ ëª©ë¡:\n" + "\n".join(f"- {t}" for t in self.todos)
        
        elif action == "remove":
            if item and item in self.todos:
                self.todos.remove(item)
                return f"'{item}' ì‚­ì œë¨"
            return f"'{item}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        elif action == "clear":
            self.todos.clear()
            return "ëª¨ë“  í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
        
        return f"ì•Œ ìˆ˜ ì—†ëŠ” ì•¡ì…˜: {action}"


# ì‚¬ìš©
todo_tool = TodoListTool()
agent = CodeAgent(tools=[todo_tool], model=InferenceClientModel())

agent.run("í•  ì¼ ëª©ë¡ì— 'ë³´ê³ ì„œ ì‘ì„±', 'ì´ë©”ì¼ í™•ì¸', 'ë¯¸íŒ… ì°¸ì„'ì„ ì¶”ê°€í•´ì¤˜")
agent.run("í˜„ì¬ í•  ì¼ ëª©ë¡ì„ ë³´ì—¬ì¤˜")
```

### 4.5 Hubì—ì„œ Tool ë¡œë“œ

```python
from smolagents import load_tool, CodeAgent, InferenceClientModel

# Hubì—ì„œ Tool ë¡œë“œ
image_tool = load_tool(
    "m-ric/text-to-image",
    trust_remote_code=True,
)

agent = CodeAgent(
    tools=[image_tool],
    model=InferenceClientModel(),
)

result = agent.run("ìš°ì£¼ì—ì„œ ë³¸ ì§€êµ¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì¤˜")
```

### 4.6 Hub Spaceë¥¼ Toolë¡œ ì‚¬ìš©

```python
from smolagents import Tool, CodeAgent, InferenceClientModel

# Gradio Spaceë¥¼ Toolë¡œ ë³€í™˜
image_generation_tool = Tool.from_space(
    "black-forest-labs/FLUX.1-schnell",
    name="image_generator",
    description="í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤",
)

agent = CodeAgent(
    tools=[image_generation_tool],
    model=InferenceClientModel(),
)

result = agent.run("ê·€ì—¬ìš´ ê³ ì–‘ì´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì¤˜")
```

### 4.7 LangChain Tool ì‚¬ìš©

```python
from smolagents import Tool, CodeAgent, InferenceClientModel
from langchain.agents import load_tools

# LangChain Toolì„ smolagents Toolë¡œ ë³€í™˜
search_tool = Tool.from_langchain(
    load_tools(["serpapi"])[0]
)

agent = CodeAgent(
    tools=[search_tool],
    model=InferenceClientModel(),
)

result = agent.run("BERT ì¸ì½”ë”ëŠ” ëª‡ ê°œì˜ ë ˆì´ì–´ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”?")
```

### 4.8 Toolì„ Hubì— ê³µìœ 

```python
from smolagents import tool


@tool
def reverse_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ë’¤ì§‘ìŠµë‹ˆë‹¤.
    
    Args:
        text: ë’¤ì§‘ì„ í…ìŠ¤íŠ¸
    
    Returns:
        ë’¤ì§‘íŒ í…ìŠ¤íŠ¸
    """
    return text[::-1]


# Hubì— ì—…ë¡œë“œ
reverse_text.push_to_hub("your-username/reverse-text-tool")
```

---

## 5. CodeAgent vs ToolCallingAgent

### 5.1 í•µì‹¬ ì°¨ì´ì 

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CodeAgent                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLM â”€â”€â–¶ [Python ì½”ë“œ ìƒì„±] â”€â”€â–¶ [ì½”ë“œ ì‹¤í–‰] â”€â”€â–¶ ê²°ê³¼        â”‚
â”‚                                                             â”‚
â”‚  ì˜ˆì‹œ:                                                       â”‚
â”‚  result = web_search("ë‚ ì”¨ ì„œìš¸")                            â”‚
â”‚  temperature = parse_temperature(result)                    â”‚
â”‚  final_answer(f"ì„œìš¸ ì˜¨ë„: {temperature}Â°C")                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ToolCallingAgent                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLM â”€â”€â–¶ [JSON Tool Call ìƒì„±] â”€â”€â–¶ [Tool ì‹¤í–‰] â”€â”€â–¶ ê²°ê³¼     â”‚
â”‚                                                             â”‚
â”‚  ì˜ˆì‹œ:                                                       â”‚
â”‚  {                                                          â”‚
â”‚    "tool": "web_search",                                    â”‚
â”‚    "arguments": {"query": "ë‚ ì”¨ ì„œìš¸"}                       â”‚
â”‚  }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 ë¹„êµí‘œ

| íŠ¹ì„± | CodeAgent | ToolCallingAgent |
|------|-----------|------------------|
| **ì•¡ì…˜ í˜•ì‹** | Python ì½”ë“œ | JSON/Text |
| **í‘œí˜„ë ¥** | ë†’ìŒ (ë£¨í”„, ì¡°ê±´ë¬¸, ë³€ìˆ˜) | ì œí•œì  |
| **ìœ ì—°ì„±** | ë™ì  ë¡œì§ ê°€ëŠ¥ | ì‚¬ì „ ì •ì˜ëœ ì•¡ì…˜ë§Œ |
| **ë³´ì•ˆ ìœ„í—˜** | ë†’ìŒ (ì½”ë“œ ì‹¤í–‰) | ë‚®ìŒ |
| **ë””ë²„ê¹…** | ë³µì¡í•  ìˆ˜ ìˆìŒ | ì˜ˆì¸¡ ê°€ëŠ¥ |
| **íš¨ìœ¨ì„±** | ~30% ì ì€ ìŠ¤í… | ë” ë§ì€ ìŠ¤í… í•„ìš” |
| **ê¶Œì¥ ìš©ë„** | ë³µì¡í•œ ì—°ì‚°, ë°ì´í„° ì²˜ë¦¬ | ê°„ë‹¨í•œ API í˜¸ì¶œ |

### 5.3 CodeAgent ì‚¬ìš©

```python
from smolagents import CodeAgent, InferenceClientModel, DuckDuckGoSearchTool

model = InferenceClientModel()

# CodeAgent: Python ì½”ë“œë¡œ ì•¡ì…˜ ì‹¤í–‰
code_agent = CodeAgent(
    tools=[DuckDuckGoSearchTool()],
    model=model,
    add_base_tools=True,  # ê¸°ë³¸ ë„êµ¬ ì¶”ê°€
)

# ë³µì¡í•œ ì—°ì‚°ì´ í•„ìš”í•œ íƒœìŠ¤í¬
result = code_agent.run("""
í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì˜ ì²˜ìŒ 20ê°œ ìˆ«ìë¥¼ ê³„ì‚°í•˜ê³ ,
ê·¸ ì¤‘ ì§ìˆ˜ì¸ ê²ƒë“¤ì˜ í•©ì„ êµ¬í•´ì¤˜.
""")
print(result)
```

**CodeAgent ì‹¤í–‰ ì˜ˆì‹œ:**
```python
# Agentê°€ ìƒì„±í•œ ì½”ë“œ
def fibonacci(n):
    fib = [0, 1]
    for i in range(2, n):
        fib.append(fib[-1] + fib[-2])
    return fib

fib_20 = fibonacci(20)
even_sum = sum(x for x in fib_20 if x % 2 == 0)
final_answer(f"í”¼ë³´ë‚˜ì¹˜ ì²˜ìŒ 20ê°œ ì¤‘ ì§ìˆ˜ì˜ í•©: {even_sum}")
```

### 5.4 ToolCallingAgent ì‚¬ìš©

```python
from smolagents import ToolCallingAgent, InferenceClientModel, tool


@tool
def get_stock_price(symbol: str) -> str:
    """ì£¼ì‹ ê°€ê²©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        symbol: ì£¼ì‹ ì‹¬ë³¼ (ì˜ˆ: AAPL, GOOGL)
    
    Returns:
        í˜„ì¬ ì£¼ê°€ ì •ë³´
    """
    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ
    prices = {"AAPL": 175.50, "GOOGL": 140.25, "MSFT": 380.00}
    price = prices.get(symbol.upper())
    if price:
        return f"{symbol}: ${price}"
    return f"{symbol} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


model = InferenceClientModel()

# ToolCallingAgent: JSON ê¸°ë°˜ Tool í˜¸ì¶œ
tool_agent = ToolCallingAgent(
    tools=[get_stock_price],
    model=model,
)

result = tool_agent.run("ì• í”Œê³¼ êµ¬ê¸€ì˜ í˜„ì¬ ì£¼ê°€ë¥¼ ì•Œë ¤ì¤˜")
print(result)
```

### 5.5 CodeAgent ì¶”ê°€ ì„¤ì •

```python
from smolagents import CodeAgent, InferenceClientModel

model = InferenceClientModel()

agent = CodeAgent(
    tools=[],
    model=model,
    # ì¶”ê°€ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ í—ˆìš©
    additional_authorized_imports=["requests", "bs4", "pandas", "numpy"],
    # ìµœëŒ€ ì‹¤í–‰ ìŠ¤í…
    max_steps=10,
    # ê¸°ë³¸ ë„êµ¬ ì¶”ê°€ (web_search, python_interpreter ë“±)
    add_base_tools=True,
    # ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë°
    stream_outputs=True,
)

# ì›¹ ìŠ¤í¬ë˜í•‘ ì˜ˆì‹œ
result = agent.run("""
https://huggingface.co/blog í˜ì´ì§€ì—ì„œ 
ì²« ë²ˆì§¸ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ì œëª©ì„ ê°€ì ¸ì™€ì¤˜.
requestsì™€ bs4ë¥¼ ì‚¬ìš©í•´.
""")
```

### 5.6 E2B ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ (ë³´ì•ˆ)

```python
import os
from smolagents import CodeAgent, InferenceClientModel

# E2B API í‚¤ ì„¤ì •
os.environ["E2B_API_KEY"] = "your-e2b-api-key"

model = InferenceClientModel()

# E2B ìƒŒë“œë°•ìŠ¤ì—ì„œ ì½”ë“œ ì‹¤í–‰
agent = CodeAgent(
    tools=[],
    model=model,
    use_e2b_executor=True,  # E2B ìƒŒë“œë°•ìŠ¤ ì‚¬ìš©
)

result = agent.run("ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì¶œë ¥í•´ì¤˜")
```

---

## 6. Multi-Agent ì‹œìŠ¤í…œ

### 6.1 ManagedAgent ê°œë…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Manager Agent                             â”‚
â”‚                        â”‚                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚           â”‚           â”‚           â”‚                        â”‚
â”‚           â–¼           â–¼           â–¼                        â”‚
â”‚     [Web Agent]  [Code Agent]  [Research Agent]            â”‚
â”‚           â”‚           â”‚           â”‚                        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                       â”‚                                    â”‚
â”‚                       â–¼                                    â”‚
â”‚                 Final Answer                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 ê¸°ë³¸ Multi-Agent êµ¬í˜„

```python
from smolagents import (
    CodeAgent,
    ToolCallingAgent,
    ManagedAgent,
    InferenceClientModel,
    DuckDuckGoSearchTool,
    tool,
)


# ëª¨ë¸ ì´ˆê¸°í™”
model = InferenceClientModel()


# 1. ì›¹ ê²€ìƒ‰ ì „ë¬¸ Agent
web_agent = CodeAgent(
    tools=[DuckDuckGoSearchTool()],
    model=model,
)

# ManagedAgentë¡œ ë˜í•‘
managed_web_agent = ManagedAgent(
    agent=web_agent,
    name="web_search_agent",
    description="ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì¸ìë¡œ ì „ë‹¬í•˜ì„¸ìš”.",
)


# 2. ê³„ì‚° ì „ë¬¸ Agent
@tool
def calculator(expression: str) -> str:
    """ìˆ˜í•™ í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        expression: ê³„ì‚°í•  ìˆ˜í•™ í‘œí˜„ì‹
    
    Returns:
        ê³„ì‚° ê²°ê³¼
    """
    try:
        result = eval(expression)
        return str(result)
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {e}"


calc_agent = CodeAgent(
    tools=[calculator],
    model=model,
)

managed_calc_agent = ManagedAgent(
    agent=calc_agent,
    name="calculator_agent",
    description="ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ìˆ˜í•™ í‘œí˜„ì‹ì„ ì „ë‹¬í•˜ì„¸ìš”.",
)


# 3. Manager Agent
manager_agent = CodeAgent(
    tools=[],
    model=model,
    managed_agents=[managed_web_agent, managed_calc_agent],
)

# ì‹¤í–‰
result = manager_agent.run("""
ëŒ€í•œë¯¼êµ­ì˜ ì¸êµ¬ìˆ˜ë¥¼ ê²€ìƒ‰í•˜ê³ ,
ê·¸ ì¸êµ¬ë¥¼ 1000ìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì„ ê³„ì‚°í•´ì¤˜.
""")
print(result)
```

### 6.3 ì „ë¬¸í™”ëœ Agent íŒ€

```python
from smolagents import CodeAgent, ManagedAgent, InferenceClientModel, tool


model = InferenceClientModel()


# ë²ˆì—­ Agent
@tool
def translate(text: str, target_lang: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•©ë‹ˆë‹¤.
    
    Args:
        text: ë²ˆì—­í•  í…ìŠ¤íŠ¸
        target_lang: ëª©í‘œ ì–¸ì–´ (ì˜ˆ: 'en', 'ko', 'ja')
    
    Returns:
        ë²ˆì—­ëœ í…ìŠ¤íŠ¸
    """
    # ì‹¤ì œë¡œëŠ” ë²ˆì—­ API í˜¸ì¶œ
    return f"[{target_lang}ë¡œ ë²ˆì—­ë¨] {text}"


translator_agent = CodeAgent(tools=[translate], model=model)
managed_translator = ManagedAgent(
    agent=translator_agent,
    name="translator",
    description="í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤.",
)


# ìš”ì•½ Agent
@tool
def summarize(text: str, max_sentences: int = 3) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    
    Args:
        text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        max_sentences: ìµœëŒ€ ë¬¸ì¥ ìˆ˜
    
    Returns:
        ìš”ì•½ëœ í…ìŠ¤íŠ¸
    """
    sentences = text.split(".")[:max_sentences]
    return ". ".join(sentences) + "."


summarizer_agent = CodeAgent(tools=[summarize], model=model)
managed_summarizer = ManagedAgent(
    agent=summarizer_agent,
    name="summarizer",
    description="ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì§§ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.",
)


# Orchestrator Agent
orchestrator = CodeAgent(
    tools=[],
    model=model,
    managed_agents=[managed_translator, managed_summarizer],
    planning_interval=3,  # 3ìŠ¤í…ë§ˆë‹¤ ê³„íš ì¬ìˆ˜ë¦½
)

result = orchestrator.run("""
ë‹¤ìŒ ì˜ì–´ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ê³ , 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:
"Artificial intelligence is transforming how we work and live. 
Machine learning models can now understand natural language, 
generate images, and even write code. The possibilities are endless,
but we must also consider the ethical implications of these technologies."
""")
print(result)
```

---

## 7. ê¸°ë³¸ ì œê³µ Tool

### 7.1 ë‚´ì¥ Tool ëª©ë¡

```python
from smolagents import CodeAgent, InferenceClientModel

model = InferenceClientModel()

# add_base_tools=Trueë¡œ ê¸°ë³¸ ë„êµ¬ ì¶”ê°€
agent = CodeAgent(
    tools=[],
    model=model,
    add_base_tools=True,
)

# ì¶”ê°€ë˜ëŠ” ê¸°ë³¸ ë„êµ¬ë“¤:
# - DuckDuckGoSearchTool: ì›¹ ê²€ìƒ‰
# - PythonInterpreterTool: Python ì½”ë“œ ì‹¤í–‰ (ToolCallingAgentìš©)
# - Transcriber: ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜ (Whisper)
```

### 7.2 DuckDuckGoSearchTool

```python
from smolagents import DuckDuckGoSearchTool

search_tool = DuckDuckGoSearchTool()

# ì§ì ‘ ì‚¬ìš©
result = search_tool("Python 3.12 ìƒˆë¡œìš´ ê¸°ëŠ¥")
print(result)
```

### 7.3 VisitWebpageTool

```python
from smolagents import VisitWebpageTool

webpage_tool = VisitWebpageTool()

# ì›¹í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
content = webpage_tool("https://huggingface.co/blog")
print(content[:500])
```

### 7.4 Tool Collection ì‚¬ìš©

```python
from smolagents import ToolCollection, CodeAgent, InferenceClientModel

# Hubì—ì„œ Tool Collection ë¡œë“œ
image_tools = ToolCollection(
    collection_slug="huggingface-tools/diffusion-tools-6630bb19a942c2306a2cdb6f",
    token="YOUR_HF_TOKEN",
)

agent = CodeAgent(
    tools=[*image_tools.tools],
    model=InferenceClientModel(),
    add_base_tools=True,
)

result = agent.run("ê°•ê³¼ í˜¸ìˆ˜ê°€ ìˆëŠ” í’ê²½ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì¤˜")
```

---

## 8. Gradio UI í†µí•©

### 8.1 ê¸°ë³¸ UI

```python
from smolagents import CodeAgent, InferenceClientModel, DuckDuckGoSearchTool
from smolagents import GradioUI

model = InferenceClientModel()
agent = CodeAgent(
    tools=[DuckDuckGoSearchTool()],
    model=model,
)

# Gradio UI ì‹¤í–‰
GradioUI(agent).launch()
```

### 8.2 ì»¤ìŠ¤í…€ UI ì„¤ì •

```python
from smolagents import GradioUI

# ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ UI ì‹¤í–‰
ui = GradioUI(
    agent,
    file_upload_folder="./uploads",  # íŒŒì¼ ì—…ë¡œë“œ í´ë”
)
ui.launch(
    share=True,       # ê³µê°œ ë§í¬ ìƒì„±
    server_port=7860, # í¬íŠ¸ ì„¤ì •
)
```

---

## 9. Agentë¥¼ Hubì— ê³µìœ 

### 9.1 Agent ì €ì¥ ë° ë¡œë“œ

```python
from smolagents import CodeAgent, InferenceClientModel, tool


@tool
def my_custom_tool(text: str) -> str:
    """ì»¤ìŠ¤í…€ ë„êµ¬ì…ë‹ˆë‹¤."""
    return f"ì²˜ë¦¬ë¨: {text}"


# Agent ìƒì„±
agent = CodeAgent(
    tools=[my_custom_tool],
    model=InferenceClientModel(),
)

# Hubì— ì—…ë¡œë“œ
agent.push_to_hub("your-username/my-awesome-agent")

# Hubì—ì„œ ë¡œë“œ
from smolagents import load_agent

loaded_agent = load_agent("your-username/my-awesome-agent")
result = loaded_agent.run("í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
```

---

## 10. ì‹¤ìŠµ ê³¼ì œ

### ê³¼ì œ 1: ë‚ ì”¨ + ë²ˆì—­ Agent
1. ë‚ ì”¨ ì¡°íšŒ Tool êµ¬í˜„ (@tool ë°ì½”ë ˆì´í„°)
2. ë²ˆì—­ Tool êµ¬í˜„ (í•œì˜/ì˜í•œ)
3. CodeAgentë¡œ "ì„œìš¸ ë‚ ì”¨ë¥¼ ì˜ì–´ë¡œ ì•Œë ¤ì¤˜" ì²˜ë¦¬

### ê³¼ì œ 2: ë°ì´í„° ë¶„ì„ Agent
1. CSV íŒŒì¼ ì½ê¸° Tool êµ¬í˜„ (Tool í´ë˜ìŠ¤)
2. ê¸°ë³¸ í†µê³„ ê³„ì‚° Tool êµ¬í˜„
3. CodeAgentë¡œ ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### ê³¼ì œ 3: Multi-Agent ì—°êµ¬ ë³´ì¡°
1. ì›¹ ê²€ìƒ‰ Agent (ManagedAgent)
2. ìš”ì•½ Agent (ManagedAgent)
3. Manager Agentë¡œ "ìµœì‹  LLM íŠ¸ë Œë“œ ë¦¬ì„œì¹˜" ìˆ˜í–‰

---

## 11. ìš”ì•½ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Agent ê¸°ë³¸
- [ ] smolagents ì„¤ì¹˜ ë° ì„¤ì •
- [ ] InferenceClientModel, LiteLLMModel ì‚¬ìš©
- [ ] CodeAgent ê¸°ë³¸ ì‹¤í–‰
- [ ] Tool ì¶”ê°€ ë° ì‹¤í–‰

### Tool ì •ì˜
- [ ] @tool ë°ì½”ë ˆì´í„° ì‚¬ìš©
- [ ] Tool í´ë˜ìŠ¤ ìƒì†
- [ ] Hubì—ì„œ Tool ë¡œë“œ (load_tool)
- [ ] Spaceë¥¼ Toolë¡œ ë³€í™˜ (Tool.from_space)
- [ ] LangChain Tool ë³€í™˜ (Tool.from_langchain)
- [ ] Tool Hubì— ê³µìœ  (push_to_hub)

### Agent íƒ€ì…
- [ ] CodeAgent: Python ì½”ë“œ ì‹¤í–‰
- [ ] ToolCallingAgent: JSON ê¸°ë°˜ Tool í˜¸ì¶œ
- [ ] ë³´ì•ˆ ì„¤ì • (E2B, additional_authorized_imports)

### Multi-Agent
- [ ] ManagedAgent ìƒì„±
- [ ] Manager Agent êµ¬ì„±
- [ ] Agent ê³„ì¸µ êµ¬ì¡° ì„¤ê³„

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- **smolagents GitHub**: https://github.com/huggingface/smolagents
- **smolagents Documentation**: https://huggingface.co/docs/smolagents
- **smolagents Blog**: https://huggingface.co/blog/smolagents

### íŠœí† ë¦¬ì–¼
- **HF Agents Course**: https://huggingface.co/learn/agents-course
- **HF Cookbook - Agents**: https://huggingface.co/learn/cookbook/en/agents
- **Guided Tour**: https://smolagents.org/docs/agents-guided-tour/

### ëª¨ë¸
- **InferenceClientModel ì§€ì› ëª¨ë¸**: https://huggingface.co/models?inference=warm
- **LiteLLM ì§€ì› ëª¨ë¸**: https://docs.litellm.ai/docs/providers

---

## ë‹¤ìŒ ë‹¨ê³„

**Part 5.2: Custom Tool Development**ì—ì„œ ë‹¤ë£° ë‚´ìš©:
- Vision/Search/Code ì‹¤í–‰ Tool ì‹¬í™”
- MCP (Model Context Protocol) í†µí•©
- RAG Tool êµ¬í˜„
- í”„ë¡œë•ì…˜ ë°°í¬ ê³ ë ¤ì‚¬í•­